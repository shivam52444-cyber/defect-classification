{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52fb309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84c655",
   "metadata": {},
   "source": [
    "# dataset is abot crack in concrete or not\n",
    "it is a classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2326c4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0519e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_dir=\"C:/Users/Satyam/Downloads/Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255f3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_dir=\"C:/Users/Satyam/Downloads/Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "930f6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory):\n",
    "    images=[]\n",
    "    for filename in os.listdir(directory):\n",
    "        img_path=os.path.join(directory,filename)\n",
    "        img=cv2.imread(img_path)\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images=load_images(positive_dir)\n",
    "negative_images=load_images(negative_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2376deaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images_train=positive_images[6000:7000]\n",
    "negative_images_train=negative_images[6000:7000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805636e2",
   "metadata": {},
   "source": [
    "# here we scaled data between [0,1]\n",
    "scalling is required because here we use ResNet50, and REsnet is pre traineed on scalled data\n",
    "scalling is also rquired because it heps model to prevnt overfitting\n",
    "scallin converts the pixels in between[0-1] it makes easier to convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe1de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=[]\n",
    "def make_norm(abcd):\n",
    "    for image in abcd:\n",
    "        image=image.astype(np.float32)\n",
    "        normalized_image=image/255.0\n",
    "        imgs.append(normalized_image)\n",
    "    return imgs\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4171dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de82c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images_train=np.array(make_norm(positive_images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea0a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7777862a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dac0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_images_train=np.array((negative_images_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111217df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.concatenate([positive_images_train,negative_images_train],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734b85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=(np.concatenate([np.ones(len(positive_images_train)),np.zeros(len(negative_images_train))],axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d5eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083313bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6694c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c08b34",
   "metadata": {},
   "source": [
    "We imported ResNet50  a pretrained model for this classification task, this model is family of ResNet model, and it have 50 layers,\n",
    "so it is callled ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9321a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model=tf.keras.applications.ResNet50(weights='imagenet',include_top=False,input_shape=(227,227,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373eb3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f258ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c46fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=GlobalAveragePooling2D()(resnet_model.output)\n",
    "a=Dense(128,activation='relu')(a)\n",
    "predictions=Dense(1,activation='sigmoid')(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bec23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=resnet_model.input,outputs=predictions)\n",
    "for layers in resnet_model.layers:\n",
    "    layers.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c52bf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001),loss='binary_crossentropy',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc566f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_val=np.array(positive_images[1000:2000])\n",
    "neg_val=np.array(negative_images[1000:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=np.concatenate([pos_val,neg_val],axis=0)\n",
    "y_val=y=np.concatenate([np.array(np.ones(len(pos_val))),np.array(np.zeros(len(neg_val)))],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347129ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x,y,epochs=1,batch_size=62,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71690a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_batch_generator(a,b,batch_size=32):\n",
    "    num_classes=len(np.unique(b))\n",
    "    class_indices=[np.where(b==i)[0] for i in range(num_classes)]\n",
    "    class_count=[len(indices) for indices in class_indices]\n",
    "    while True:\n",
    "        batch_indices=[]\n",
    "        for i in range(batch_size//2):\n",
    "            class_index=np.random.randint(num_classes)\n",
    "            indices=class_indices[class_index]\n",
    "            index=np.random.choice(indices)\n",
    "            batch_indices.append(index)\n",
    "        yield a[batch_indices],b[batch_indices]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf3c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=62\n",
    "train_generator=balanced_batch_generator(x,y,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa4b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epochs=len(x)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397659a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks\n",
    "early_stopping=callbacks.EarlyStopping(monitor='val_loss',patience=3,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c62b4",
   "metadata": {},
   "source": [
    "it is always good to experiment with No of epochs,early_stopping,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22654f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_generator,\n",
    "                 steps_per_epoch=steps_per_epochs,\n",
    "                 epochs=3,\n",
    "                 validation_data=((x_val,y_val)),\n",
    "                 callbacks=[early_stopping]\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2cf587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "train_acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c78acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss,label='trainig_loss')\n",
    "plt.plot(val_loss,label='validation_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a1386",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_acc,label='trainning Accuracy')\n",
    "plt.plot(val_acc,label='validation_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f998dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_test=np.array(positive_images[3000:3050])\n",
    "negative_test=np.array(negative_images[7850:7900])\n",
    "positive_pred=model.predict(positive_test)\n",
    "\n",
    "threshold=.45\n",
    "pos_predicted_label=(positive_pred>threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80abdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "precision=precision_score(np.ones(50),pos_predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f588b",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall=recall_score(np.ones(50),pos_predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7664737",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf99e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f1aa01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
